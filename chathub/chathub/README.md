# âš¡ ChatHub â€” Multi-Provider AI Chat

Um hub de chat que conecta mÃºltiplos modelos de IA (Claude, GPT-4o, Gemini, Mistral, Llama 3) em uma interface unificada estilo ChatGPT.

![ChatHub](https://img.shields.io/badge/React-18-blue) ![Vite](https://img.shields.io/badge/Vite-6-purple) ![Deploy](https://img.shields.io/badge/Deploy-Vercel-black)

## âœ¨ Funcionalidades

- ðŸ” **Sistema de login/cadastro** com senha criptografada (SHA-256)
- ðŸ’¬ **Meus Chats** â€” histÃ³rico completo salvo localmente
- ðŸ¤– **5 Providers de IA** â€” Claude, GPT-4o, Gemini, Mistral, Llama 3 (via Groq)
- ðŸ“¡ **Broadcast Mode** â€” envie para todos os modelos e compare respostas
- âš™ï¸ **ConfiguraÃ§Ã£o de API Keys** â€” cada usuÃ¡rio conecta suas prÃ³prias keys
- ðŸ”‘ **Teste de conexÃ£o** â€” valide suas keys antes de usar
- ðŸ” **Busca nos chats** â€” encontre conversas antigas rapidamente
- âœï¸ **Renomear chats** â€” duplo-clique no tÃ­tulo para editar
- ðŸ’¾ **PersistÃªncia total** â€” tudo salvo no localStorage por usuÃ¡rio

## ðŸš€ Deploy RÃ¡pido (Vercel â€” Recomendado)

### PrÃ©-requisitos
- Conta no [GitHub](https://github.com)
- Conta no [Vercel](https://vercel.com) (grÃ¡tis)

### Passo a passo

#### 1. Suba para o GitHub

```bash
# Na pasta do projeto
cd chathub

# Inicie o git
git init
git add .
git commit -m "ChatHub initial commit"

# Crie um repositÃ³rio no GitHub e conecte
git remote add origin https://github.com/SEU_USUARIO/chathub.git
git branch -M main
git push -u origin main
```

#### 2. Deploy no Vercel

1. Acesse [vercel.com](https://vercel.com) e faÃ§a login com GitHub
2. Clique **"Add New" â†’ "Project"**
3. Selecione o repositÃ³rio `chathub`
4. O Vercel detecta automaticamente o Vite â€” clique **"Deploy"**
5. Aguarde ~1 minuto. Pronto! Seu ChatHub estarÃ¡ em `https://chathub-xxx.vercel.app`

#### 3. Configure um domÃ­nio (opcional)

No dashboard do Vercel â†’ Settings â†’ Domains â†’ adicione seu domÃ­nio personalizado.

## ðŸ› ï¸ Desenvolvimento Local

```bash
# Clone o projeto
git clone https://github.com/SEU_USUARIO/chathub.git
cd chathub

# Instale dependÃªncias
npm install

# Rode em modo desenvolvimento
npm run dev

# Acesse http://localhost:3000
```

Em desenvolvimento, o Vite proxy cuida do CORS automaticamente.
Em produÃ§Ã£o (Vercel), a serverless function `api/chat.js` faz o proxy.

## ðŸ“ Estrutura do Projeto

```
chathub/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ chat.js          # Serverless function (proxy para APIs)
â”œâ”€â”€ public/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.js           # Chamadas para cada provider
â”‚   â”œâ”€â”€ App.jsx          # Componente principal (auth + chat)
â”‚   â”œâ”€â”€ index.css        # Estilos globais e animaÃ§Ãµes
â”‚   â”œâ”€â”€ main.jsx         # Entry point React
â”‚   â”œâ”€â”€ providers.js     # ConfiguraÃ§Ã£o dos providers
â”‚   â””â”€â”€ storage.js       # UtilitÃ¡rios de persistÃªncia (localStorage)
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â”œâ”€â”€ vercel.json          # ConfiguraÃ§Ã£o Vercel
â””â”€â”€ vite.config.js       # ConfiguraÃ§Ã£o Vite + proxies dev
```

## ðŸ”Œ Providers Suportados

| Provider | Modelo | Onde obter a API Key |
|----------|--------|---------------------|
| **Claude** | claude-sonnet-4-20250514 | [console.anthropic.com](https://console.anthropic.com/) |
| **GPT-4o** | gpt-4o | [platform.openai.com](https://platform.openai.com/api-keys) |
| **Gemini** | gemini-2.0-flash | [aistudio.google.com](https://aistudio.google.com/apikey) |
| **Mistral** | mistral-large-latest | [console.mistral.ai](https://console.mistral.ai/api-keys/) |
| **Llama 3** | llama-3.3-70b-versatile | [console.groq.com](https://console.groq.com/keys) |

## ðŸ”’ SeguranÃ§a

- API keys ficam salvas **apenas no localStorage do navegador** de cada usuÃ¡rio
- Em produÃ§Ã£o, as chamadas passam pela serverless function do Vercel (server-side), evitando exposiÃ§Ã£o de keys no client
- Senhas sÃ£o hasheadas com SHA-256 antes de salvar
- Nenhum dado Ã© enviado a servidores externos alÃ©m dos prÃ³prios providers de IA

## ðŸŽ¨ PersonalizaÃ§Ã£o

### Adicionar um novo provider

1. Adicione o provider em `src/providers.js`
2. Implemente a funÃ§Ã£o de chamada em `src/api.js`
3. Adicione o case correspondente em `api/chat.js`

### Alterar tema/cores

As cores sÃ£o definidas inline nos componentes. Os tokens principais:
- Background: `#131316`
- Surface: `#18181C`, `#1A1A1F`, `#1E1E22`
- Borders: `#2A2A30`
- Accent: `#E8D5B7`, `#C9A96E` (dourado)
- Text: `#E8E6E3`, `#F0EDE8`

## ðŸ“‹ Alternativas de Deploy

### Netlify

```bash
npm run build
# Arraste a pasta `dist/` para netlify.com/drop
# Adicione um arquivo netlify/functions/chat.js com a mesma lÃ³gica do api/chat.js
```

### Railway / Render

Use como um servidor Node.js. Adicione um `server.js`:

```js
import express from 'express';
import { handler } from './api/chat.js';

const app = express();
app.use(express.json());
app.use(express.static('dist'));
app.post('/api/chat', handler);
app.get('*', (req, res) => res.sendFile('dist/index.html'));
app.listen(process.env.PORT || 3000);
```

### Docker

```dockerfile
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build
EXPOSE 3000
CMD ["node", "server.js"]
```

## ðŸ“„ LicenÃ§a

MIT â€” use, modifique e distribua livremente.
